{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#RegEx\" data-toc-modified-id=\"RegEx-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>RegEx</a></span><ul class=\"toc-item\"><li><span><a href=\"#Special-Characters\" data-toc-modified-id=\"Special-Characters-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Special Characters</a></span></li><li><span><a href=\"#Capture-Groups\" data-toc-modified-id=\"Capture-Groups-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Capture Groups</a></span></li><li><span><a href=\"#Negative-Character-Classes\" data-toc-modified-id=\"Negative-Character-Classes-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Negative Character Classes</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Word-Boundary-Anchor\" data-toc-modified-id=\"Word-Boundary-Anchor-1.3.0.1\"><span class=\"toc-item-num\">1.3.0.1&nbsp;&nbsp;</span>Word Boundary Anchor</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Continuing-RegEx\" data-toc-modified-id=\"Continuing-RegEx-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Continuing RegEx</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lookarounds\" data-toc-modified-id=\"Lookarounds-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Lookarounds</a></span></li><li><span><a href=\"#Backreferences\" data-toc-modified-id=\"Backreferences-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Backreferences</a></span></li><li><span><a href=\"#re.sub()\" data-toc-modified-id=\"re.sub()-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>re.sub()</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Extracting-Domains-and-URLs\" data-toc-modified-id=\"Extracting-Domains-and-URLs-2.3.0.1\"><span class=\"toc-item-num\">2.3.0.1&nbsp;&nbsp;</span>Extracting Domains and URLs</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegEx\n",
    "\n",
    "Regular Expressions are a powerful way of building patterns to matching text. In the first two missions of this Data Cleaning Advanced course, we're going to extend our knowledge about this extremely powerful tool that every data scientist should be familiar with.\n",
    "\n",
    "As powerful as regular expressions are, they can be difficult to learn at first and the syntax can look visually intimidating. As a result, a lot of students end up disliking regular expressions and try to avoid using them, instead opting to write more cumbersome code.\n",
    "\n",
    "`(.+)://([\\w\\.]+)/?(.*)`\n",
    "\n",
    "That said, learning (and loving!) regular expressions is something that is a worthwhile investment\n",
    "\n",
    "- Once you understand how they work, complex operations with string data can be written a lot quicker, which will save you time.\n",
    "- Regular expressions are often faster to execute than their manual equivalents.\n",
    "- Regular expressions are supported in almost every modern programming language, as well as other places like command line utilities and databases. Understanding regular expressions gives you a powerful tool that you can use wherever you work with data.\n",
    "\n",
    "One thing to keep in mind before we start: don't expect to remember all of the regular expression syntax. The most important thing is to understand the core principles, what is possible, and where to look up the details. This will mean you can quickly jog your memory whenever you need regular expressions.\n",
    "\n",
    "With that in mind, don't be put off if some things in these missions don't stick in your memory. As long as you are able to write and understand regular expressions with the help of documentation and/or other reference guides, you have all the skills you need to excel.\n",
    "\n",
    "When working with regular expressions, we use the term **pattern** to describe a regular expression that we've written. If the pattern is found within the string we're searching, we say that it has **matched**.\n",
    "\n",
    "As we previously learned, letters and numbers represent themselves in regular expressions. If we wanted to find the string `\"and\"` within another string, the regex pattern for that is simply `and`:\n",
    "\n",
    "|RegEx|String      |Matches              |String with match|\n",
    "|-----|------------|---------------------|-----------------|\n",
    "| and |hand        |yes                  |h`and`           |\n",
    "| and |android     |yes                  |`and`roid        |\n",
    "| and |Andrew      |no                   |                 |\n",
    "| and |antidote    |no                   |                 |\n",
    "\n",
    "\n",
    "In the third example above, the pattern `and` does not match `Andrew` because even though `a` and `A` are the same letter, the two characters are unique.\n",
    "\n",
    "We previously used regular expressions with pandas, but Python also has a built-in module for regular expressions: The `re` [module](https://docs.python.org/3/library/re.html#module-re). This module contains a number of different functions and classes for working with regular expressions. One of the most useful functions from the `re` module is the `re.search()` [function](https://docs.python.org/3/library/re.html#re.search), which takes two required arguments:\n",
    "\n",
    "- The regex pattern\n",
    "- The string we want to search that pattern for\n",
    "\n",
    "`import re\n",
    "m = re.search(\"and\", \"hand\")\n",
    "print(m)`\n",
    "\n",
    "`< _sre.SRE_Match object; span=(1, 4), match='and' >`\n",
    "\n",
    "The `re.search()` function will return a `Match` [object](https://docs.python.org/3/library/re.html#match-objects) if the pattern is found anywhere within the string. If the pattern is not found, `re.search()` returns `None`:\n",
    "\n",
    "`m = re.search(\"and\", \"antidote\")\n",
    "print(m)`\n",
    "\n",
    "`None`\n",
    "\n",
    "We'll learn more about match objects later. For now, we can use the fact that the boolean value of a match object is `True` while `None` is `False` to easily check whether our regex matches each string in a list. We'll create a list of three simple strings to use while learning these concepts:\n",
    "\n",
    "`string_list = [\"Julie's favorite color is Blue.\",\n",
    "               \"Keli's favorite color is Green.\",\n",
    "               \"Craig's favorite colors are blue and red.\"]`\n",
    "\n",
    "`pattern = \"Blue\"`\n",
    "\n",
    "`for s in string_list:\n",
    "    if re.search(pattern, s):\n",
    "        print(\"Match\")\n",
    "    else:\n",
    "        print(\"No Match\")`\n",
    "        \n",
    "`Match\n",
    "No Match\n",
    "No Match`\n",
    "\n",
    "So far, we haven't done anything with regular expressions that we couldn't do using the `in` keyword. The power of regular expressions comes when we use one of the special character sequences.\n",
    "\n",
    "The first of these we'll learn is called a **set**. A set allows us to specify two or more characters that can match in a single character's position.\n",
    "\n",
    "We define a set by placing the characters we want to match for in square brackets:\n",
    "\n",
    "`[msb]end`\n",
    "\n",
    "- `[` - Start Set\n",
    "- `]` - End Set\n",
    "- `msb` - Look for `m`, `s`, or `b`\n",
    "- `end` - the substring end\n",
    "\n",
    "The regular expression above will match the strings `mend`, `send`, and `bend`.\n",
    "\n",
    "If you look closely, you'll notice the first string contains the substring `Blue` with a capital letter, where the third string contains the substring `blue` in all lowercase. We can use the set `[Bb]` for the first character so that we can match both variations, and then use that to count how many times `Blue` or `blue` occur in the list:\n",
    "\n",
    "`blue_mentions = 0\n",
    "pattern = \"[Bb]lue\"`\n",
    "\n",
    "`for s in string_list:\n",
    "    if re.search(pattern, s):\n",
    "        blue_mentions += 1`\n",
    "\n",
    "`print(blue_mentions)`\n",
    "\n",
    "`2`\n",
    "\n",
    "We've learned that we should avoid using loops in pandas, and that vectorized methods are often faster and require less code.\n",
    "\n",
    "In the data cleaning course, we learned that the `Series.str.contains()` [method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html) can be used to test whether a Series of strings match a particular regex pattern. Let's look at how we can replicate the example from the previous screen using pandas.\n",
    "\n",
    "We'll start by creating a pandas object containing our strings:\n",
    "\n",
    "`eg_list = [\"Julie's favorite color is green.\",\n",
    "           \"Keli's favorite color is Blue.\",\n",
    "           \"Craig's favorite colors are blue and red.\"]`\n",
    "\n",
    "`eg_series = pd.Series(eg_list)\n",
    "print(eg_series)`\n",
    "\n",
    "Next, we'll create our regex pattern, and use `Series.str.contains()` to compare to each value in our series:\n",
    "\n",
    "`pattern = \"[Bb]lue\"`\n",
    "\n",
    "`pattern_contained = eg_series.str.contains(pattern)\n",
    "print(pattern_contained)`\n",
    "\n",
    "The result is a boolean mask: a series of `True`/`False` values.\n",
    "\n",
    "One of the neat things about boolean masks is that you can use the `Series.sum()` [method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.sum.html) to sum all the values in the boolean mask, with each `True` value counting as `1`, and each `False` as `0`. This means that we can easily count the number of values in the original series that matched our pattern:\n",
    "\n",
    "`pattern_count = pattern_contained.sum()\n",
    "print(pattern_count)`\n",
    "\n",
    "`2`\n",
    "\n",
    "**Check this main**\n",
    "\n",
    "`pattern = '[Pp]ython'\n",
    "titles = hn[\"title\"].tolist()\n",
    "python_mentions = pd.Series(titles).str.contains(pattern).sum()`\n",
    "\n",
    "On the previous two screens, we used regular expressions to count how many titles contain `Python` or `python`. What if we wanted to view those titles?\n",
    "\n",
    "In that case, we can use the boolean array returned by `Series.str.contains()` to select just those rows from our series. Let's look at that in action, starting by creating the boolean array.\n",
    "\n",
    "Then, we can use that boolean array to select just the matching rows:\n",
    "\n",
    "`py_titles = titles[py_titles_bool]`\n",
    "\n",
    "We can also do it in a streamlined, single line of code:\n",
    "\n",
    "`py_titles = titles[titles.str.contains(\"[Pp]ython\")]\n",
    "print(py_titles.head())`\n",
    "\n",
    "Let's use this technique to select all titles that mention the programming language Ruby, using a set to account for whether the word is capitalized or not.\n",
    "\n",
    "`titles = hn['title']\n",
    "ruby_titles = titles[titles.str.contains(\"[Rr]uby\")]`\n",
    "\n",
    "In the data cleaning course, we learned that we could use braces (`{}`) to specify that a character repeats in our regular expression. For instance, if we wanted to write a pattern that matches the numbers in text from `1000` to `2999` we could write the regular expression below:\n",
    "\n",
    "`[1-2][0-9]{3}`\n",
    "\n",
    "- `[1-2]` - Any digit between 1 and 2\n",
    "- `[0-9]` - Any digit between 0 and 9\n",
    "- `{3}` - Repeat the previous range 3 times \n",
    "\n",
    "The name for this type of regular expression syntax is called a **quantifier**. Quantifiers specify how many of the previous character our pattern requires, which can help us when we want to match substrings of specific lengths. As an example, we might want to match both `e-mail` and `email`. To do this, we would want to specify to match `-` either zero or one times.\n",
    "\n",
    "The specific type of quantifier we saw above is called a numeric quantifier. Here are the different types of numeric quantifiers we can use:\n",
    "\n",
    "|Quantifier|Pattern     |Explanation                         |\n",
    "|----------|------------|------------------------------------|\n",
    "| numeric  |`a{3}`      |Character `a` 3 times               |\n",
    "| numeric  |`a{3,5}`    |Character `a` 3, 4, OR 5 times      |\n",
    "| numeric  |`a{,3}`     |Character `a` 0, 1, 2, OR 3 times   |\n",
    "| numeric  |`a{8,}`     |Character `a` 8 or more             |\n",
    "\n",
    "You might notice that the last two examples above omit the first and last character as wildcards, in the same way that we can omit the first or last indicies when slicing lists.\n",
    "\n",
    "In addition to numeric quantifiers, there are single characters in regex that specify some common quantifiers that you're likely to use. A summary of them is below.\n",
    "\n",
    "|Quantifier|Pattern     |Equivalent       |\n",
    "|----------|------------|-----------------|\n",
    "| numeric  |`a{0,}`     |`a*`             |\n",
    "| numeric  |`a{1,}`     |`a+`             |\n",
    "| numeric  |`a{0,1}`    |`a?`             |\n",
    "\n",
    "\n",
    "So far, we've learned how to perform simple matches with sets, and how to use quantifiers to specify when a character should repeat a certain number of times. Let's continue by looking at a more complex example.\n",
    "\n",
    "Some stories submitted to Hacker News include a topic tag in brackets, like `[pdf]`. Here are a few examples of story titles with these tags:\n",
    "\n",
    "To match the substring `\"[pdf]\"`, we can use backslashes to escape both the open and closing brackets: `\\[pdf\\]`.\n",
    "\n",
    "`\\[pdf\\]`\n",
    "\n",
    "- `\\[` - The `[` character (escaped)\n",
    "- `pdf` - The entire substring `pdf`\n",
    "- `\\]` - The `]` character (escaped)\n",
    "\n",
    "The other critical part of our task of identifying how many titles have tags is knowing how to match the characters between the brackets (like `pdf` and `video`) without knowing ahead of time what the different topic tags will be.\n",
    "\n",
    "To match unknown characters using regular expressions, we use **character classes**. Character classes allow us to match certain groups of characters. We've actually seen two examples of character classes already:\n",
    "\n",
    "1. The set notation using brackets to match any of a number of characters.\n",
    "2. The range notation, which we used to match ranges of digits (like [0-9]).\n",
    "\n",
    "Let's look at a summary of syntax for some of the regex character classes:\n",
    "\n",
    "|Character Class |Pattern     |Explanation                          |\n",
    "|----------------|------------|-------------------------------------|\n",
    "| Set            |`[fud]`     |Either, `f`,`u`, or `d`              |\n",
    "| Range          |`[a-e]`     |Any chars between `a` through `e`    |\n",
    "| Range          |`[0-3]`     |Any chars between `0` through `3`    |\n",
    "| Range          |`[A-Z]`     |Any Uppercase Character              |\n",
    "| Set + Range    |`[A-Za-z]`  |Any Uppercase or lowercase Character |\n",
    "\n",
    "There are two new things we can observe from this table:\n",
    "\n",
    "1. Ranges can be used for letters as well as numbers.\n",
    "2. Sets and ranges can be combined.\n",
    "\n",
    "Just like with quantifiers, there are some other common character classes which we'll use a lot.\n",
    "\n",
    "|Character Class |Pattern  |Explanation                                                  |\n",
    "|----------------|---------|-------------------------------------------------------------|\n",
    "| Digit          |`\\d`     |Any digit character (same as `[0-9]`                         |\n",
    "| Word           |`\\w`     |Any digit, upper/lower/underscore (same as `[A-Za-z0-9_]`    |\n",
    "| Whitespace     |`\\s`     |Any space, tab, or linebreak character                       |\n",
    "| Dot            |`. `     |Any character except newline                                 |\n",
    "\n",
    "The one that we'll be using in order to match characters in tags is `\\w`, which represents any digit uppercase or lowercase letter. Each character class represents a single character, so to match multiple characters (e.g. words like `video` and `pdf`), we'll need to combine them with quantifiers.\n",
    "\n",
    "In order to match word characters between our brackets, we can combine the word character class (`\\w`) with the 'one or more' quantifier (`+`), giving us a combined pattern of `\\w+`.\n",
    "\n",
    "This will match sequences like `pdf`, `video`, `Python`, and `2018` but won't match a sequence containing a space or punctuation character like `PHP-DEV` or `XKCD Flowchart`. If we wanted to match those tags as well, we could use `.+`; however, in this case, we're just interested in single-word tags without special characters.\n",
    "\n",
    "Let's quickly recap the concepts we learned in this screen:\n",
    "\n",
    "- We can use a backslash to escape characters that have special meaning in regular expressions (e.g. \\ will match an open bracket character).\n",
    "- Character classes let us match certain groups of characters (e.g. \\w will match any word character).\n",
    "- Character classes can be combined with quantifiers when we want to match different numbers of characters.\n",
    "\n",
    "We'll use these concepts to count the number of titles that contain a tag.\n",
    "\n",
    "Use the regular expression to select only items from that match. Assign the result to the variable tag_titles.\n",
    "\n",
    "`pattern = \"\\[\\w+\\]\"\n",
    "tag_titles = titles[titles.str.contains(pattern)]\n",
    "tag_count = titles.str.contains(pattern).sum()`\n",
    "\n",
    "## Special Characters\n",
    "On the previous screen, we learned that we can use backslashes to escape the `[` and `]` characters. Backslashes are used to escape many other characters in regular expressions, as well as to denote some special character sequences (like character classes).\n",
    "\n",
    "In Python, a backslash followed by certain characters represents an [escape sequence](https://en.wikipedia.org/wiki/Escape_sequences_in_C#Table_of_escape_sequences) — like the `\\n` sequence — which we previously learned represents a new line. These escape sequences can result in unintended consequences for our regular expressions. Let's take a look at a string containing the substring `\\b`:\n",
    "\n",
    "`print('hello\\b')`\n",
    "\n",
    "`hell`\n",
    "\n",
    "The escape sequence `\\b` represents a backspace, so the final letter from our string is removed. The character sequence `\\b` has a special meaning in regular expressions (which we'll learn about later), so we need a way to write these characters without triggering the escape sequence.\n",
    "\n",
    "One way is to add an extra backslash before the \"b\":\n",
    "\n",
    "`print('hello\\\\b')`\n",
    "\n",
    "`hello\\b`\n",
    "\n",
    "This can make regular expressions even more difficult to read and interpret, so instead we use [raw strings](https://docs.python.org/3/reference/lexical_analysis.html#string-and-bytes-literals), which we denote by prefixing our string with the `r` character. Let's take a look at the code from above with a raw string:\n",
    "\n",
    "`print(r'hello\\b')`\n",
    "\n",
    "`hello\\b`\n",
    "\n",
    "## Capture Groups\n",
    "We strongly recommend using raw strings for every regex you write, rather than remember which sequences are escape sequences and using raw strings selectively. That way, you'll never encounter a situation where you forget or overlook something which causes your regex to break.\n",
    "\n",
    "In the previous screen, we were able to calculate that 444 of the 20,100 Hacker News stories in our dataset contain tags. What if we wanted to find out what the text of these tags were, and how many of each are in the dataset?\n",
    "\n",
    "In order to do this, we'll need to use **capture groups**. Capture groups allow us to specify one or more groups within our match that we can access separately. In this mission, we'll learn how to use one capture group per regular expression, but in the next mission we'll learn some more complex capture group patterns.\n",
    "\n",
    "We specify capture groups using parentheses. Let's add an open and close parentheses to the pattern we wrote in the previous screen, and break down how each character in our regular expression works:\n",
    "\n",
    "`(\\[\\w+\\])`\n",
    "\n",
    "- `(` - Start capture group\n",
    "- `\\[` - The character `[` (escaped)\n",
    "- `\\w+` - One or more word characters\n",
    "- `\\]` - The `]` character (escaped)\n",
    "- `)` - End capture group\n",
    "\n",
    "We'll learn how to access capture groups in pandas by looking at just the first five matching titles from the previous exercise:\n",
    "\n",
    "`tag_5 = tag_titles.head()\n",
    "print(tag_5)`\n",
    "\n",
    "We use the `Series.str.extract()` [method](https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.Series.str.extract.html) to extract the match within our parentheses:\n",
    "\n",
    "`pattern = r\"(\\[\\w+\\])\"\n",
    "tag_5_matches = tag_5.str.extract(pattern)\n",
    "print(tag_5_matches)`\n",
    "\n",
    "We can move our parentheses inside the brackets to get just the text:\n",
    "\n",
    "`pattern = r\"\\[(\\w+)\\]\"\n",
    "tag_5_matches = tag_5.str.extract(pattern)\n",
    "print(tag_5_matches)`\n",
    "\n",
    "If we then use `Series.value_counts()` we can quickly get a frequency table of the tags:\n",
    "\n",
    "`tag_5_freq = tag_5_matches.value_counts()\n",
    "print(tag_5_freq)`\n",
    "\n",
    "**Finding all of the things that match in this joint**\n",
    "\n",
    "`\n",
    "pattern = r\"\\[(\\w+)\\]\"\n",
    "tag_freq = df.str.extract(pattern).value_counts()`\n",
    "\n",
    "On the previous screens, we wrote mostly simple regular expressions. In reality, regular expressions are often complex. When creating complex regular expressions, you often need to work iteratively so you can find \"bad\" instances that match your pattern and then exclude them.\n",
    "\n",
    "In order to work faster as you build your regular expression, it can be helpful to create a function that returns the first few matching strings:\n",
    "\n",
    "Another useful approach is to use an online tool like [RegExr](https://regexr.com/) that allows you to build regular expressions and includes syntax highlighting, instant matches, and regex syntax reference. For this screen, we'll use the `first_10_matches` function we just built to iteratively build a regular expression.\n",
    "\n",
    "Earlier, we counted the titles that included Python — let's write a simple regular expression to match Java (another popular language), and use our function to look at the matches:\n",
    "\n",
    "`first_10_matches(r\"[Jj]ava\")`\n",
    "\n",
    "We can see that there are a number of matches that contain `Java` as part of the word `JavaScript`. We want to exclude these titles from matching so we get an accurate count.\n",
    "\n",
    "One way to do this is by using **negative character classes**. Negative character classes are character classes that match every character except a character class. Let's look at a table of the common negative character classes:\n",
    "\n",
    "## Negative Character Classes\n",
    "\n",
    "|Character Class |Pattern     |Explanation                               |\n",
    "|----------------|------------|------------------------------------------|\n",
    "| Negative Set   |`[^fud]`    |Any char except `f`,`u`, or `d`           |\n",
    "| Negative Set   |`[^1-3Z\\s]` |Any char except `1-3`,`Z`, & `whitespace` |\n",
    "| Negative Digit |`\\D`        |Any char except digital characters        |\n",
    "| Negative Word  |`\\W`        |Any char except word characters           |  \n",
    "| Negative WhiteS|`\\S`        |Any char except whitespace characters     |\n",
    "\n",
    "Let's use the negative set `[^Ss]` to exclude instances like JavaScript and Javascript:\n",
    "\n",
    "On the previous screen, we used a negative set to find all of the mentions of \"Java\" in our dataset:\n",
    "\n",
    "`first_10_matches(r\"[Jj]ava[^Ss]\")`\n",
    "\n",
    "While the negative set was effective in removing any bad matches that mention JavaScript, it also had the side-effect of removing any titles where `Java` occurs at the end of the string, like this title:\n",
    "\n",
    "`Pippo  Web framework in Java`\n",
    "\n",
    "This is because the negative set `[^Ss]` must match one character, so instances at the end of a string do not match.\n",
    "\n",
    "#### Word Boundary Anchor\n",
    "A different approach to take in cases like these is to use the **word boundary anchor**, specified using the syntax `\\b`. A word boundary matches the position between a word character and a non-word character, or a word character and the start/end of a string. The diagram below shows all the word boundaries in an example string:\n",
    "\n",
    "Let's look at how using a word boundary changes the match from the string in the example above:\n",
    "\n",
    "`string = \"Sometimes people confuse JavaScript with Java\"\n",
    "pattern_1 = r\"Java[^S]\"`\n",
    "\n",
    "`m1 = re.search(pattern_1, string)\n",
    "print(m1)`\n",
    "\n",
    "`None`\n",
    "\n",
    "The regular expression returns `None`, because there is no substring that contains `Java` followed by a character that isn't `S`.\n",
    "\n",
    "Let's instead use word boundaries in our regular expression:\n",
    "\n",
    "`pattern_2 = r\"\\bJava\\b\"`\n",
    "\n",
    "`m2 = re.search(pattern_2, string)\n",
    "print(m2)`\n",
    "\n",
    "`_sre.SRE_Match object; span=(41, 45), match='Java'`\n",
    "\n",
    "With the word boundary, our pattern matches the `Java` at the end of the string.\n",
    "\n",
    "Let's use the word boundary anchor as part of our regular expression to select the titles that mention Java.\n",
    "\n",
    "`pattern = r'\\b[Jj]ava\\b'\n",
    "java_titles = titles[titles.str.contains(pattern)]`\n",
    "\n",
    "So far, we've used regular expressions to match substrings contained anywhere within text. There are often scenarios where we want to specifically match a pattern at the start and end of strings.\n",
    "\n",
    "On the previous screen, we learned that the **word boundary anchor** matches the space between a word character and a non-word character. More generally in regular expressions, an **anchor** matches something that isn't a character, as opposed to character classes which match specific characters.\n",
    "\n",
    "Other than the word boundary anchor, the other two most common anchors are the **beginning anchor** and the **end anchor**, which represent the start and the end of the string, respectfully.\n",
    "\n",
    "|Anchor          |Pattern     |Explanation                                    |\n",
    "|----------------|------------|-----------------------------------------------|\n",
    "| Beginning      |`^abc`      |Matches `abc` only at the start of the string  |\n",
    "| End            |`abc$`      |Matches `abc` only at the end of the string    |\n",
    "\n",
    "Note that the `^` character is used both as a beginning anchor and to indicate a negative set, depending on whether the character preceding it is a `[` or not.\n",
    "\n",
    "Let's start with a few test cases that all contain the substring `Red` at different parts of the string, as well as a test function:\n",
    "\n",
    "`pattern_beg = r'^\\[(\\w+)\\]'\n",
    "beginning_count = titles.str.contains(pattern_beg).sum()`\n",
    "\n",
    "`pattern_end = r'\\[(\\w+)\\]$'\n",
    "ending_count = titles.str.contains(pattern_end).sum()`\n",
    "\n",
    "Up until now, we've been using sets like [Pp] to match different capitalizations in our regular expressions. This strategy works well when there is only one character that has capitalization, but becomes cumbersome when we need to cater for multiple instances.\n",
    "\n",
    "Within the titles, there are many different formatting styles used to represent the word \"email.\" Here is a list of the variations:\n",
    "\n",
    "`email\n",
    "Email\n",
    "e Mail\n",
    "e mail\n",
    "E-mail\n",
    "e-mail\n",
    "eMail\n",
    "E-Mail\n",
    "EMAIL`\n",
    "\n",
    "To write a regular expression for this, we would need to use a set for all five letters in email, which would make our regular expression very hard to read.\n",
    "\n",
    "Instead, we can use `flags` to specify that our regular expression should ignore case.\n",
    "\n",
    "Both `re.search()` and the pandas regular expression methods accept an optional `flags` argument. This argument accepts one or more flags, which are special variables in the re module that modify the behavior of the regex interpreter.\n",
    "\n",
    "A [list of all available flags](https://docs.python.org/3/library/re.html#re.A) is in the documentation, but by far the most common and the most useful is the `re.IGNORECASE` `flag`, which is also available using the alias `re.I` for convenience.\n",
    "\n",
    "When you use this flag, all uppercase letters will match their lowercase equivalents and vice versa. Let's look at an example without using the flag:\n",
    "\n",
    "`email_tests = pd.Series(['email', 'Email', 'eMail', 'EMAIL'])\n",
    "email_tests.str.contains(r\"email\")`\n",
    "\n",
    "Now let's look at what happens when we use the flag:\n",
    "\n",
    "`import re\n",
    "email_tests.str.contains(r\"email\",flags=re.I)`\n",
    "\n",
    "No matter what the capitalization is, our regular expression matches.\n",
    "\n",
    "We'll finish this mission by writing a regular expression and count the number of times that email is mentioned in story titles. You'll need to use both ignorecase as well as some of the other regex components you've already learned in this mission.\n",
    "\n",
    "In this mission, we learned the basics of using regular expressions to perform powerful text matching, including:\n",
    "\n",
    "- Character classes to match certain groups of characters, including sets to match different capitalizations of programming languages.\n",
    "- Quantifiers to match different quantities of characters, including matching different variations of \"email.\"\n",
    "- Negative character classes for matching anything except certain groups of characters.\n",
    "- Word boundaries to match only specific instances of words.\n",
    "- Positional anchors to match only at the start and end of strings.\n",
    "- The ignorecase flag to make patterns case insensitive.\n",
    "\n",
    "In the next mission, we'll expand on our regular expression knowledge with some advanced regex concepts!\n",
    "\n",
    "# Continuing RegEx\n",
    "\n",
    "So far we've used capture groups to extract all or most of the text in our regular expression pattern. Capture groups can also be useful to extract specific data from within our expression.\n",
    "\n",
    "Let's look at a sample of Hacker News titles that mention Python:\n",
    "\n",
    "`Developing a computational pipeline using the asyncio module in Python 3\n",
    "Python 3 on Google App Engine flexible environment now in beta\n",
    "Python 3.6 proposal, PEP 525: Asynchronous Generators\n",
    "How async/await works in Python 3.5.0\n",
    "Ubuntu Drops Python 2.7 from the Default Install in 16.04`\n",
    "\n",
    "All of these examples have a number after the word \"Python,\" which indicates a version number. We can use the following regular expression to match these cases:\n",
    "\n",
    "`[Pp]ython [\\d\\.]+`\n",
    "\n",
    "- `[Pp]` - Upper or Lowercase `P`\n",
    "- `[ython]` - The substring `ython`\n",
    "- `[\\d\\.]+` - One or more digits OR `.` chars\n",
    "\n",
    "We can use capture groups to extract the version of Python that is mentioned most often in our dataset by wrapping parentheses around the part of our regular expression which captures the version number.\n",
    "\n",
    "We'll use a capture group to capture the version number after the word \"Python,\" and then build a frequency table of the different versions.\n",
    "\n",
    "`pattern=r'[Pp]ython ([\\d\\.]+)'`\n",
    "`py_versions_freq = dict(titles.str.extract(pattern, flags=re.I).value_counts())`\n",
    "\n",
    "It looks like we're getting close. In our first 10 matches we have one irrelevant result, which is about \"Series C,\" a term used to represent a particular type of startup fundraising.\n",
    "\n",
    "Additionally, we've run into the same issue as we did in the previous mission — by using a negative set, we may have eliminated any instances where the last character of the title is \"C\" (the second last line of output matches in spite of the fact that it ends with \"C,\" because it also has \"C\" earlier in the string).\n",
    "\n",
    "Neither of these can be avoided using negative sets, which are used to allow multiple matches for a single character. Instead we'll need a new tool: **lookarounds**.\n",
    "\n",
    "## Lookarounds\n",
    "\n",
    "Lookarounds let us define a character or sequence of characters that either must or must not come before or after our regex match. There are four types of lookarounds:\n",
    "\n",
    "|Lookaround      |Pattern       |Explanation                                  |\n",
    "|----------------|--------------|---------------------------------------------|\n",
    "| + Lookahead    |`zzz(?=abc)`  |Matches `zzz` when its followed by abc       |\n",
    "| - Lookahead    |`zzz(!?=abc)` |Matches `zzz` when its NOT followed by abc   |\n",
    "| + Lookabehind  |`(?<=abc)zzz` |Matches `zzz` when its before abc            |\n",
    "| - Lookabehind  |`(?<!=abc)zzz`|Matches `zzz` when its NOT before abc        |\n",
    "\n",
    "These tips can help you remember the syntax for lookarounds:\n",
    "\n",
    "- Inside the parentheses, the first character of a lookaround is always ?.\n",
    "- If the lookaround is a lookbehind, the next character will be <, which you can think of as an arrow head pointing behind the match.\n",
    "- The next character indicates whether the is lookaround is positive (=) or negative (!).\n",
    "\n",
    "Let's create some test data that we'll use to illustrate how lookarounds work:\n",
    "\n",
    "`test_cases = ['Red_Green_Blue',\n",
    "              'Yellow_Green_Red',\n",
    "              'Red_Green_Red',\n",
    "              'Yellow_Green_Blue',\n",
    "              'Green']`\n",
    "\n",
    "We'll also create a function that will loop over our test cases and tell us whether our pattern matches. We'll use the `re` module rather than pandas since it tells us the exact text that matches, which will help us understand how the lookaround is working:\n",
    "\n",
    "`def run_test_cases(pattern):\n",
    "    for tc in test_cases:\n",
    "        result = re.search(pattern, tc)\n",
    "        print(result or \"NO MATCH\")`\n",
    "        \n",
    "In each instance, we'll aim to match the substring `Green` depending on the characters that precede or follow it. Let's start by using a **positive lookahead** to include instances where the match is followed by the substring `_Blue`. We'll include the underscore character in the lookahead, otherwise we will get zero matches:\n",
    "\n",
    "The contents of a lookaround can include any other regular expression component. For instance, here is an example where we match only cases that are followed by exactly five characters:\n",
    "\n",
    "`run_test_cases(r\"Green(?=.{5})\")`\n",
    "\n",
    "The second and third test cases are followed by four characters, not five, and the last test case isn't followed by anything.\n",
    "\n",
    "Sometimes programming languages won't implement support for all lookarounds (notably, lookbehinds are not in the official JavaScript specification). As an example, to get full support in the `RegExr` tool, you'll need to set it to use the PCRE regex engine.\n",
    "\n",
    "In this exercise, we're going to use lookarounds to refine the regular expression we build on the last screen to capture mentions of the \"C\" programming language. As a reminder, here is the last of the regular expressions we attempted to use with this exercise earlier, and the resultant titles that match:\n",
    "\n",
    "`first_10_matches(r\"\\b[Cc]\\b[^.+]\")`\n",
    "\n",
    "Let's now use lookarounds to exclude the matches we don't want. We want to:\n",
    "\n",
    "- Keep excluding matches that are followed by . or +, but still match cases where \"C\" falls at the end of the string.\n",
    "- Exclude matches that have the word 'Series' immediately preceding them.\n",
    "\n",
    "This exercise is a little harder than those you've seen so far in this course — it's okay if it takes you a few attempts!\n",
    "\n",
    "## Backreferences\n",
    "Let's say we wanted to identify strings that had words with double letters, like the \"ee\" in \"feed.\" Because we don't know ahead of time what letters might be repeated, we need a way to specify a capture group and then to repeat it. We can do this with **backreferences**.\n",
    "\n",
    "Whenever we have one or more capture groups, we can refer to them using integers left to right as shown in this regex that matches the string `HelloGoodbye`:\n",
    "\n",
    "`(Hello)(Goodbye)`\n",
    "\n",
    "Within a regular expression, we can use a backslash followed by that integer to refer to the group:\n",
    "\n",
    "`(Hello)(Goodbye)\\2\\1`\n",
    "\n",
    "The regular expression above will match the text `HelloGoodbyeGoodbyeHello`. Let's look at how we could write a regex to capture instances of the same two word characters in a row:\n",
    "\n",
    "`(\\w)\\1`\n",
    "\n",
    "Notice that there was no match for the word Aaron, despite it containing a double \"a.\" This is because the uppercase and lowercase \"a\" are two different characters, so the backreference does not match.\n",
    "\n",
    "We can easily achieve the same thing using pandas:\n",
    "\n",
    "Let's use this technique to identify story titles that have repeated words.\n",
    "\n",
    "## re.sub()\n",
    "When we learned to work with basic string methods, we used the `str.replace()` method to replace simple substrings. We can achieve the same with regular expressions using the `re.sub()` [function](https://docs.python.org/3/library/re.html#re.sub). The basic syntax for `re.sub()` is:\n",
    "\n",
    "`re.sub(pattern, repl, string, flags=0)`\n",
    "\n",
    "The `repl` parameter is the text that you would like to substitute for the match. Let's look at a simple example where we replace all capital letters in a string with dashes:\n",
    "\n",
    "`string = \"aBcDEfGHIj\"\n",
    "print(re.sub(r\"[A-Z]\", \"-\", string))`\n",
    "\n",
    "`a-c--f---j`\n",
    "\n",
    "Earlier, we discovered that there were multiple different capitalizations for SQL in our dataset. Let's look at how we could make these uniform with the `Series.str.replace()` method and a regular expression:\n",
    "\n",
    "`sql_variations = pd.Series([\"SQL\", \"Sql\", \"sql\"])`\n",
    "\n",
    "`sql_uniform = sql_variations.str.replace(r\"sql\", \"SQL\", flags=re.I)\n",
    "print(sql_uniform)`\n",
    "\n",
    "`pattern = r'e[-\\s]{0,1}mail'`\n",
    "\n",
    "`email_uniform = email_variations.str.replace(pattern, \"email\", flags=re.I)\n",
    "titles_clean =  titles.str.replace(pattern, \"email\", flags=re.I)`\n",
    "\n",
    "Over the final three screens in this mission, we'll extract components of URLs from our dataset. As a reminder, most stories on Hacker News contain a link to an external resource.\n",
    "\n",
    "The task we will be performing first is extracting the different components of the URLs in order to analyze them. On this screen, we'll start by extracting just the domains. Below is a list of some of the URLs in the dataset, with the domains highlighted in color, so you can see the part of the string we want to capture.\n",
    "\n",
    "`https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429,\n",
    " http://www.interactivedynamicvideo.com/\n",
    " http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0\n",
    " http://evonomics.com/advertising-cannot-maintain-internet-heres-solution/\n",
    " HTTPS://github.com/keppel/pinn\n",
    " Http://phys.org/news/2015-09-scale-solar-youve.html\n",
    " https://iot.seeed.cc\n",
    " http://www.bfilipek.com/2016/04/custom-deleters-for-c-smart-pointers.html\n",
    " http://beta.crowdfireapp.com/?beta=agnipath\n",
    " https://www.valid.ly?param`\n",
    " \n",
    "The domain of each URL excludes the protocol (e.g. https://) and the page path (e.g. /Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429).\n",
    " \n",
    "There are several ways that you could use regular expressions to extract the domain, but we suggest the following technique:\n",
    "\n",
    "- Using a series of characters that will match the protocol.\n",
    "- Inside a capture group, using a set that will match the character classes used in the domain.\n",
    "- Because all of the URLs either end with the domain, or continue with page path which starts with / (a character not found in any domains), we don't need to cater for this part of the URL in our regular expression.\n",
    "\n",
    "Once you have extracted the domains, you will be building a frequency table so we can determine the most popular domains. There are over 7,000 unique domains in our dataset, so to make the frequency table easier to analyze, we'll look at only the top 20 domains.\n",
    "\n",
    "We have provided some of the URLs from the dataset which will help you to iterate while you build your regular expression.\n",
    "\n",
    "#### Extracting Domains and URLs\n",
    "The task we will be performing first is extracting the different components of the URLs in order to analyze them. On this screen, we'll start by extracting just the domains. Below is a list of some of the URLs in the dataset, with the domains highlighted in color, so you can see the part of the string we want to capture.\n",
    "\n",
    "` 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
    " 'http://www.interactivedynamicvideo.com/',\n",
    " 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
    " 'http://evonomics.com/advertising-cannot-maintain-internet-heres-solution/',\n",
    " 'HTTPS://github.com/keppel/pinn',\n",
    " 'Http://phys.org/news/2015-09-scale-solar-youve.html',\n",
    " 'https://iot.seeed.cc',\n",
    " 'http://www.bfilipek.com/2016/04/custom-deleters-for-c-smart-pointers.html',\n",
    " 'http://beta.crowdfireapp.com/?beta=agnipath',\n",
    " 'https://www.valid.ly?param'`\n",
    " \n",
    "The domain of each URL excludes the protocol `(e.g. https://)` and the page path (e.g. /Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429).\n",
    "\n",
    "**Pattern to extract domains from urls**\n",
    "`pattern = r'https?://([\\w\\.]+)'`\n",
    "\n",
    "Having extracted just the domains from the URLs, on this final screen we'll extract each of the three component parts of the URLs:\n",
    "\n",
    "- Protocol\n",
    "- Domain\n",
    "- Page path\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
